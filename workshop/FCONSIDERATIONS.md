# Fairness Considerations

> This document contains the question set for the second session of our workshop series. Organisations can also use these questions to understand their RAI (responsible AI) implementation challenges.

**Main focus:** What are the main challenges of developers/system owners while integrating fairness toolkits/techniques into their workflow?

**Fairness Evaluation and Mitigation:**

- Who is responsible for identifying potential fairness issues in your ML systems, and how is this responsibility distributed?
- Are there formal processes for gathering feedback on fairness from users or affected communities? Are there clear lines of responsibility for implementing and monitoring fairness mitigation measures?
- How do you ensure that fairness evaluations are conducted throughout the entire ML lifecycle, from data collection to deployment and monitoring?
- When fairness issues are identified, what is the process for implementing mitigation strategies? How do you ensure that fairness mitigation strategies are effective and do not introduce new biases?
- How do you handle situations where there are conflicting fairness goals? What kind of resources are given to teams to assist with fairness mitigation?

**General Collaboration:**

- How often does the tech team collaborate with other departments (e.g., legal, ethics, social sciences) during the ML development lifecycle?
- What are the primary channels of communication between the tech team and other stakeholders regarding fairness concerns?
- How are decisions regarding fairness trade-offs made, and who is involved in those decisions?
- How do you involve stakeholders in the design process to prevent “confirmation” and “representation” biases?
- Considering these points, what are the needs of SMEs in different TRL levels? What tools and assessments do you use in your workflow? 

**Assessing RAI Frameworks/Practices:**

- Which Responsible AI (RAI) frameworks or guidelines or industry standards does your organization follow?
- How are these principles integrated into your organization's ML development processes? Are there formal policies or procedures for ensuring adherence to RAI frameworks?
- How do you document your organization's efforts to address fairness and other RAI concerns? How do you ensure that your ML systems comply with relevant regulations and ethical standards?
- How does your organization stay up-to-date on the latest developments in RAI research and best practices?

**Challenges and Improvements:**

- What are the factors you feel are barriers and challenges to implementing trustworthy AI?
- As an AI developer, what do you expect to support trustworthy AI? Is this something that is organisationally-driven, individually-driven or both, and why?
- What is your interpretation of transparency? How would you define transparency as an AI developer? What are some methods/best practices to ensure transparency in an AI system life- cycle?
- How do you measure the success of your organization's RAI initiatives?

