{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Experiments using Azure Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asabuncuoglu/Documents/fairness-monitoring/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ChanceFocus/flare-fiqasa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'query', 'answer', 'text', 'choices', 'gold'],\n",
       "        num_rows: 750\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'query', 'answer', 'text', 'choices', 'gold'],\n",
       "        num_rows: 235\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['id', 'query', 'answer', 'text', 'choices', 'gold'],\n",
       "        num_rows: 188\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the sentiment of the following financial headline: Positive, Negative, or Neutral?\n",
      "Text: Greene King's third quarter sales boosted by festive season\n",
      "Answer:\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][\"query\"][1])\n",
    "print(dataset[\"train\"][\"answer\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use AzureMLChatOnlineEndPoint to send structured prompt to Azure LLM Endpoint and get a formatted response using langchain community library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.chat_models.azureml_endpoint import AzureMLChatOnlineEndpoint, AzureMLEndpointApiType, LlamaChatContentFormatter\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = AzureMLChatOnlineEndpoint(\n",
    "    endpoint_url= os.environ.get(\"MISTRAL_LARGE_ENDPOINT_URL\"),\n",
    "    endpoint_api_type=AzureMLEndpointApiType.serverless, \n",
    "    endpoint_api_key= os.environ.get(\"MISTRAL_LARGE_ENDPOINT_API_KEY\"),\n",
    "    content_formatter=LlamaChatContentFormatter(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The sentiment of the post is Neutral. The author acknowledges that the numbers for $LULU looked good, but not great, showing a balanced perspective. They also express optimism about the conference call, which might seem positive. However, their overall tone is more speculative and uncertain, rather than definitively positive or negative. Therefore, the sentiment can be best described as neutral.' type='assistant'\n"
     ]
    }
   ],
   "source": [
    "query = ''.join([dataset[\"train\"][\"query\"][0], \" Explain your reasoning.\"])\n",
    "response = chat.invoke([HumanMessage(content=query)])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below reasoning task took about 90 minutes to be completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./data/mistral-large/flare_fiqasa_reasoned_answers\n",
    "!mkdir ./data/mistral-large/flare_fiqasa_oneword_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20 queries\n",
      "Processed 40 queries\n",
      "Processed 60 queries\n",
      "Processed 80 queries\n",
      "Processed 100 queries\n",
      "Processed 120 queries\n",
      "Processed 140 queries\n",
      "Processed 160 queries\n",
      "Processed 180 queries\n",
      "Processed 200 queries\n",
      "Processed 220 queries\n",
      "Processed 240 queries\n",
      "Processed 260 queries\n",
      "Processed 280 queries\n",
      "Processed 300 queries\n",
      "Processed 320 queries\n",
      "Processed 340 queries\n",
      "Processed 360 queries\n",
      "Processed 380 queries\n",
      "Processed 400 queries\n",
      "Processed 420 queries\n",
      "Processed 440 queries\n",
      "Processed 460 queries\n",
      "Processed 480 queries\n",
      "Processed 500 queries\n",
      "Processed 520 queries\n",
      "Processed 540 queries\n",
      "Processed 560 queries\n",
      "Processed 580 queries\n",
      "Processed 600 queries\n",
      "Processed 620 queries\n",
      "Processed 640 queries\n",
      "Processed 660 queries\n",
      "Processed 680 queries\n",
      "Processed 700 queries\n",
      "Processed 720 queries\n",
      "Processed 740 queries\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary with query and response data\n",
    "data = {'query': [\"\"], 'response': [\"\"]}\n",
    "\n",
    "# Create the DataFrame object\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "for i in range(len(dataset[\"train\"][\"query\"])):\n",
    "    # Genereate response for the given query\n",
    "    try:\n",
    "        q = dataset[\"train\"][\"query\"][i]\n",
    "        chat_query = ''.join([q, \" Explain your reasoning.\"])\n",
    "        response = chat.invoke([HumanMessage(content=chat_query)])\n",
    "        # Add the response to a dataframe\n",
    "        df.loc[i] = [q, response.content]\n",
    "        if i> 0 and i % 20 == 0:\n",
    "            print(f\"Processed {i} queries\")\n",
    "            # Saving these responses to a CSV file\n",
    "            df.to_csv(\"./data/mistral-large/flare_fiqasa_reasoned_answers/flare_fiqasa_chatbot_responses_with_reasoning_{}.csv\".format(i), index=False)\n",
    "            del df\n",
    "            df = pd.DataFrame(data)\n",
    "    except OSError:\n",
    "        continue\n",
    "        # If a response is not generated/could not be allocated to memory, continue to the next query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below classifcation task took about 10 minutes to be completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20 queries\n",
      "Processed 40 queries\n",
      "Processed 60 queries\n",
      "Processed 80 queries\n",
      "Processed 100 queries\n",
      "Processed 120 queries\n",
      "Processed 140 queries\n",
      "Processed 160 queries\n",
      "Processed 180 queries\n",
      "Processed 200 queries\n",
      "Processed 240 queries\n",
      "Processed 260 queries\n",
      "Processed 280 queries\n",
      "Processed 300 queries\n",
      "Processed 320 queries\n",
      "Processed 340 queries\n",
      "Processed 360 queries\n",
      "Processed 380 queries\n",
      "Processed 400 queries\n",
      "Processed 420 queries\n",
      "Processed 440 queries\n",
      "Processed 460 queries\n",
      "Processed 480 queries\n",
      "Processed 500 queries\n",
      "Processed 520 queries\n",
      "Processed 540 queries\n",
      "Processed 560 queries\n",
      "Processed 580 queries\n",
      "Processed 600 queries\n",
      "Processed 620 queries\n",
      "Processed 640 queries\n",
      "Processed 660 queries\n",
      "Processed 680 queries\n",
      "Processed 700 queries\n",
      "Processed 720 queries\n",
      "Processed 740 queries\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary with query and response data\n",
    "data = {'query': [\"\"], 'response': [\"\"]}\n",
    "\n",
    "# Create the DataFrame object\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "for i in range(len(dataset[\"train\"][\"query\"])):\n",
    "    try:\n",
    "        # Genereate response for the given query\n",
    "        q = dataset[\"train\"][\"query\"][i]\n",
    "        chat_query = ''.join([q, \" Return only one word answer from this list: ['negative', 'positive', 'neutral'].\"])\n",
    "        response = chat.invoke([HumanMessage(content=chat_query)])\n",
    "        # Add the response to a dataframe\n",
    "        df.loc[i] = [q, response.content]\n",
    "        if i> 0 and i % 20 == 0:\n",
    "            print(f\"Processed {i} queries\")\n",
    "            # Saving these responses to a CSV file\n",
    "            df.to_csv(\"./data/mistral-large/flare_fiqasa_oneword_answers/flare_fiqasa_chatbot_responses_with_one_word_{}.csv\".format(i), index=False)\n",
    "            del df\n",
    "            df = pd.DataFrame(data)\n",
    "    except OSError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
